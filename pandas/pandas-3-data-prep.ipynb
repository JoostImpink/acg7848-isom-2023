{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep \n",
    "\n",
    "Data prep is about getting the dataset ready for analyzing. It involves ETL (Extract, Transform, Load), and cleaning the dataset and getting it ready: dealing with missing values, duplicate values, categorial variables, outliers, transforming variables, and adding new variables.\n",
    "Merging datasets is also part of data prep but is covered in a later notebook. Lagging values/forward values are also covered later on.\n",
    "\n",
    "These are the basic data prep tasks:\n",
    "\n",
    "- Info on datasets (describe and info methods)\n",
    "- Dealing with missing data\n",
    "- Turning categorial (factor) variables into dummy/indicator variables\n",
    "- Detecting outliers \n",
    "- Normalizing, standardizing\n",
    "- Applying functions (on rows or columns)\n",
    "- Binning (separate notebook)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info on datasets\n",
    "\n",
    "### Sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read sample dataset\n",
    "data = pd.read_csv('../datasets/feedback.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info function\n",
    "\n",
    "The info function displays a summary of the dataframe. It displays column names, data types, the number of non-null values, and memory usage.<br>\n",
    "\n",
    "__Syntax:__ DataFrame.info(verbose=None, buf=None, max_cols=None, memory_usage=None, show_counts=None, null_counts=None)<br>\n",
    "\n",
    "Where\n",
    "\n",
    "- verbose : Determines whether the full summary is to be printed. Takes a bool value.\n",
    "- buf : Determines where to send the output.\n",
    "- max_cols : Tells when to switch from verbose to truncated output. Takes int variable and if dataframe has more than max_cols, use truncated output.\n",
    "- memory_usage : Determines whether total memory usage of the dataframe elements should be displayed.\n",
    "- show_counts : Determines whether to show non-null value counts or not. A value of True will always show counts, while False never shows counts.\n",
    "\n",
    "__Return value:__ The info function does not return anything. Instead, it outputs a concise summary of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with verbose = True\n",
    "print(data.info(verbose=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column data type\n",
    "  \n",
    "- dtypes: get the data types\n",
    "- astype(): set the data type (\"float\", \"int\", \"object\" - which means string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data types\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type for price to float\n",
    "data[['price']] = data[['price']].astype(\"float\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Describe function\n",
    "\n",
    "The describe() method returns description of the data in the DataFrame.<br>\n",
    "\n",
    "__Syntax:__ DataFrame.describe(percentiles=None, include=None, exclude=None)<br>\n",
    "Here,\n",
    "- percentile: list of numbers between 0-1 for respective percentiles\n",
    "- include: list of data types to be included while describing dataframe, Default = None\n",
    "- exclude: list of data types to be excluded while describing dataframe, Default = None\n",
    "\n",
    "__Return:__ Statistical summary of data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe function on a single numerical variable\n",
    "data['number_of_reviews'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# describe function on a single string variable\n",
    "data['name'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the distinct values\n",
    "data['name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percentile list\n",
    "perc =[.20, .40, .60, .80]\n",
    "# list of dtypes to include\n",
    "incl =['object', 'float', 'int']\n",
    "# calling describe method\n",
    "myInfo = data.describe(percentiles = perc, include = incl)\n",
    "print(type(myInfo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display\n",
    "myInfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing data\n",
    "\n",
    "### Dropna function\n",
    "\n",
    "The dropna function will drop all observations that have any number of observations missing. This is quite aggressive; sometimes you may want to replace missing values with a zero, or average, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read sample dataset\n",
    "data = pd.read_csv('../datasets/feedback.csv')\n",
    "print ('number of rows in original data:', data.shape[0])\n",
    "# removing null values to avoid errors\n",
    "# inPlace = True: will change the dataframe (data) (otherwise assign it to a new dataset: data2 = data.dropna() )\n",
    "data.dropna(inplace = True)\n",
    "print ('number of observations after dropping missing values:', data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of duplicates\n",
    "print('number of observations before dropping duplicates:', data.shape[0])\n",
    "data.drop_duplicates()\n",
    "print('number of observations after dropping duplicates:', data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### isnull, notnull functions\n",
    "\n",
    "The isnull() method returns a DataFrame object where all the values are replaced with a Boolean value True for NULL values, and otherwise False.<br>\n",
    "Thus, it detects missing values for an array-like object.\n",
    "\n",
    "The notnull() method works the opposite (True if not NULL, False otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-read the data so we have all observations again (including the missing values)\n",
    "data = pd.read_csv('../datasets/feedback.csv')\n",
    "# locate missing data, note that the 'False' means that the value is not NULL\n",
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of list of booleans\n",
    "sum([True, False, False, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expand missing data of each feature and count missing values in each column\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's get the 16 observations with missing/NULL name\n",
    "# filter: data['name'].isnull()\n",
    "# results in a list of booleans (True, False), only the True values end up in the filtered dataframe\n",
    "filtered_df = data[ data['name'].isnull() ]\n",
    "print('#rows with missing name:', filtered_df.shape[0])\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing name values\n",
    "data['name'] = data['name'].fillna('Unknown name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what if price was missing, and you want to replace it with the sample-wide average?\n",
    "price_avg = data[\"price\"].mean()\n",
    "print(\"Average price:\", price_avg)\n",
    "# replace it, np.nan is the value that is replaced by price_avg\n",
    "data[\"price\"].replace(np.nan, price_avg, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turning categorial (factor) variables into dummies\n",
    "\n",
    "In the sample dataset there are three room types. Let's turn that into three dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the distinct values\n",
    "data['room_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['room_type'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy variables (new dataset)\n",
    "dummies = pd.get_dummies(data[\"room_type\"])\n",
    "dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the dummy variables to the dataset (but drop the first)\n",
    "# the reason to drop one is to have a hold-out group\n",
    "# (if a regression has an intercept then only 2 of the 3 dummies can be included in the regression)\n",
    "data = pd.get_dummies(data, columns=['room_type'], drop_first=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename variables \n",
    "data.rename(columns={'room_type_Private room':'private', 'room_type_Shared room':'shared'}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization\n",
    "\n",
    "It is the process of transforming values of several variables into a similar range. Typical normalizations include scaling the variable so the variable average is 0, the variance is 1, or the variable values range from 0 to 1.<br>\n",
    "Approach: replace original value by (original value)/(maximum value).<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's scale price such that it is between 0 and 1\n",
    "data['price_scaled'] = data['price']/data['price'].max()\n",
    "data.head()\n",
    "# note: if price also had negative values, then divide by the max of the absolute value\n",
    "# data['price_scaled'] = data['price']/data['price'].abs().max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing (mean 0, standard deviation 1)\n",
    "\n",
    "Another approach is to standardize variable such that the variable has a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "So, we subtract the mean of the variable and divide by the standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying functions (on rows or columns)\n",
    "\n",
    "### Apply function\n",
    "\n",
    "This is a function to apply to each column or row.\n",
    "\n",
    "__Syntax__ : DataFrame.apply(func, axis=0, raw=False, result_type=None, args=(), **kwargs)<br>\n",
    "\n",
    "Here,<br>\n",
    "- func - Function to apply to each column or row.<br>\n",
    "- axis{0 or ‘index’, 1 or ‘columns’}, default 0 - Axis along which the function is applied:<br>\n",
    "0 or ‘index’: apply function to each row .<br>\n",
    "1 or ‘columns’: apply function to each column.<br>    \n",
    "- rawbool, default False- Determines if row or column is passed as a Series or ndarray object:<br>\n",
    "False : passes each row or column as a Series to the function.<br>\n",
    "True : the passed function will receive ndarray objects instead.<br>\n",
    "- result_type{‘expand’, ‘reduce’, ‘broadcast’, None}, default None - These only act when axis=1 (columns):<br>\n",
    "‘expand’ : list-like results will be turned into columns.<br>\n",
    "‘reduce’ : returns a Series if possible rather than expanding list-like results. This is the opposite of ‘expand’.<br>\n",
    "‘broadcast’ : results will be broadcast to the original shape of the DataFrame, the original index and columns will be retained.<br>\n",
    "- args : tuple - Positional arguments to pass to func in addition to the array/series.\n",
    "- **kwargs : Additional keyword arguments to pass as keywords arguments to func.<br>\n",
    "\n",
    "__Returns__ : Series or DataFrame (Result of applying func along the given axis of the DataFrame)<br>\n",
    "    \n",
    "See: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "df = pd.DataFrame([[4, 9]] * 3, columns=['A', 'B'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the function on each cell\n",
    "df.apply(np.sqrt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis: 0 (default) -- sums the columns\n",
    "df.apply(np.sum, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# axis: 1 -- sums the rows\n",
    "df.apply(np.sum, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map function\n",
    "\n",
    "We can also use the map() function to apply functions on rows. <br>\n",
    "\n",
    "Let's assume we have a dataset that has gender as a string (\"M\" or \"F\"). We can reshape the data by turning this into an indicator (dummy) variable, say 1 for \"F\" and 0 otherwise.\n",
    "\n",
    "We can write a function using apply, or use the map() function. The map function will apply a function to each of the elements and returns a 'map object', which can be turned back into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map example \n",
    "my_list = [2.6743,3.63526,4.2325,5.9687967,6.3265,7.6988,8.232,9.6907]\n",
    "# apply round function to the list\n",
    "updated_list = map(round, my_list)\n",
    "# this will print a map object\n",
    "print(updated_list)\n",
    "# but this can be turned back into a list\n",
    "print(list(updated_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign data\n",
    "data = {'Name': ['Jax', 'Prince', 'Gaunther',\n",
    "                 'Emanuel', 'Ron', 'Natasha', 'Lexi'],\n",
    "        'Age': [17, 17, 18, 17, 18, 17, 17],\n",
    "        'Gender': ['M', 'M', 'M', 'M', 'M', 'F', 'F'],\n",
    "        'Marks': [90, 76, 'NaN', 74, 65, 'NaN', 71]}\n",
    " \n",
    "# Convert into DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize gender in Example 'A'\n",
    "df['Gender'] = df['Gender'].map({'M': 0,'F': 1, }).astype(int)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
